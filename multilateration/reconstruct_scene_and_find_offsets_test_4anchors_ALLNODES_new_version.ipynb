{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib wx\n",
    "import superball_multilateration_barconstraints as smb\n",
    "import numpy as np \n",
    "import rospy\n",
    "import rosbag\n",
    "from matplotlib import pylab as plt\n",
    "plt.ion()\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = ['/bbb2/0x2017_0xd','/bbb2/0x2017_0xe','/bbb2/0x2017_0xf','/bbb2/0x2017_0x10',\n",
    "          '/bbb2/0x2717_0xd','/bbb2/0x2717_0xe','/bbb2/0x2717_0xf','/bbb2/0x2717_0x10',\n",
    "          '/bbb4/0x2017_0xd','/bbb4/0x2017_0xe','/bbb4/0x2017_0xf','/bbb4/0x2017_0x10',\n",
    "          '/bbb4/0x2717_0xd','/bbb4/0x2717_0xe','/bbb4/0x2717_0xf','/bbb4/0x2717_0x10',\n",
    "          '/bbb6/0x2017_0xd','/bbb6/0x2017_0xe','/bbb6/0x2017_0xf','/bbb6/0x2017_0x10',\n",
    "          '/bbb6/0x2717_0xd','/bbb6/0x2717_0xe','/bbb6/0x2717_0xf','/bbb6/0x2717_0x10',\n",
    "          '/bbb8/0x2017_0xd','/bbb8/0x2017_0xe','/bbb8/0x2017_0xf','/bbb8/0x2017_0x10',\n",
    "          '/bbb8/0x2717_0xd','/bbb8/0x2717_0xe','/bbb8/0x2717_0xf','/bbb8/0x2717_0x10',\n",
    "          '/bbb10/0x2017_0xd','/bbb10/0x2017_0xe','/bbb10/0x2017_0xf','/bbb10/0x2017_0x10',\n",
    "          '/bbb10/0x2717_0xd','/bbb10/0x2717_0xe','/bbb10/0x2717_0xf','/bbb10/0x2717_0x10',\n",
    "          '/bbb12/0x2017_0xd','/bbb12/0x2017_0xe','/bbb12/0x2017_0xf','/bbb12/0x2017_0x10',\n",
    "          '/bbb12/0x2717_0xd','/bbb12/0x2717_0xe','/bbb12/0x2717_0xf','/bbb12/0x2717_0x10'\n",
    "         ]\n",
    "topics_node_to_node = np.array([[2,13],\n",
    "                               [2,14],\n",
    "                               [2,15],\n",
    "                               [2,16],\n",
    "                               [1,13],\n",
    "                                [1,14],\n",
    "                                [1,15],\n",
    "                                [1,16],\n",
    "                                \n",
    "                                [4,13],\n",
    "                               [4,14],\n",
    "                               [4,15],\n",
    "                               [4,16],\n",
    "                               [3,13],\n",
    "                                [3,14],\n",
    "                                [3,15],\n",
    "                                [3,16],\n",
    "                                \n",
    "                                [6,13],\n",
    "                               [6,14],\n",
    "                               [6,15],\n",
    "                               [6,16],\n",
    "                               [5,13],\n",
    "                                [5,14],\n",
    "                                [5,15],\n",
    "                                [5,16],\n",
    "                                \n",
    "                                [8,13],\n",
    "                               [8,14],\n",
    "                               [8,15],\n",
    "                               [8,16],\n",
    "                               [7,13],\n",
    "                                [7,14],\n",
    "                                [7,15],\n",
    "                                [7,16],\n",
    "                                \n",
    "                                [10,13],\n",
    "                               [10,14],\n",
    "                               [10,15],\n",
    "                               [10,16],\n",
    "                               [9,13],\n",
    "                                [9,14],\n",
    "                                [9,15],\n",
    "                                [9,16],\n",
    "                                \n",
    "                                [12,13],\n",
    "                               [12,14],\n",
    "                               [12,15],\n",
    "                               [12,16],\n",
    "                               [11,13],\n",
    "                                [11,14],\n",
    "                                [11,15],\n",
    "                                [11,16],\n",
    "                               ],dtype=int) #corresponds to topics above\n",
    "\n",
    "#topics_sensor = np.zeros(topics_node_to_node.shape,dtype=int)\n",
    "#for i in xrange(topics_node_to_node.shape[0]):\n",
    "#    topics_sensor[i] = (node_to_sensor[topics_node_to_node[i,0]],node_to_sensor[topics_node_to_node[i,1]])\n",
    "\n",
    "#1,2,4,7,8,10\n",
    "#node_indices = {1:0,2:1,13:2,14:3,15:4,16:5} #node index in distance vectors\n",
    "bag_names = []\n",
    "measured_distances = []\n",
    "node_to_sensor = []\n",
    "\n",
    "#bag_names.append(\"2015-08-27-13-25-56.bag\")\n",
    "#node_to_sensor.append({1:1,2:5,13:13,14:14,16:16})\n",
    "\n",
    "bag_names.append(\"2015-09-09-18-06-08.bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-09-09-18-06-08.bag\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n",
      "err\n"
     ]
    }
   ],
   "source": [
    "#process all bag files\n",
    "plt.close('all')\n",
    "bag_means = []\n",
    "bag_std = []\n",
    "bag_means_raw = []\n",
    "bag_stds_raw = []\n",
    "bag_means_nodes = []\n",
    "bag_std_nodes = []\n",
    "data_clean = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    print n\n",
    "    bag = rosbag.Bag(n)\n",
    "    data = {}\n",
    "    topics_mean = np.zeros(len(topics))\n",
    "    topics_std = np.zeros(len(topics))\n",
    "    plt.figure()\n",
    "    d_supahclean = []\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(4,12,i+1)\n",
    "        data = []\n",
    "        for m in bag.read_messages(topics=[t]):\n",
    "            data.append((m[1].header.stamp.to_sec(),m[1].data))\n",
    "        d = np.array(data)\n",
    "        try:\n",
    "            d_clean = d[np.where((d[:,1]>3.5)&(d[:,1]<10))[0]] #remove bad measurements\n",
    "        except:\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "            print \"err\"\n",
    "            continue\n",
    "        if(d_clean.shape[0]>10):\n",
    "            model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "            model_ransac.fit(np.arange(d_clean.shape[0]).reshape((-1,1)), d_clean)\n",
    "            inlier_mask = model_ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            m = d_clean[inlier_mask,1].mean()\n",
    "            std = d_clean[inlier_mask,1].std()\n",
    "            d_outlier = d_clean[np.where((np.abs(d_clean[:,1]-m)<3*std))[0],:]\n",
    "            topics_mean[i] = d_outlier[:,1].mean()\n",
    "            topics_std[i] = d_outlier[:,1].std()\n",
    "            #plt.plot(d_clean)\n",
    "            #plt.plot(d_clean[inlier_mask])\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'.')\n",
    "            #plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1])\n",
    "            \n",
    "            d = d_outlier.copy()\n",
    "            good_data = []\n",
    "            good_data.append(d[0])\n",
    "            v_d = np.zeros(d.shape)\n",
    "            for i in xrange(1,d.shape[0]):\n",
    "                t_1 = good_data[-1][0]\n",
    "                t = d[i,0]\n",
    "                p_1 = good_data[-1][1]\n",
    "                p = d[i,1]\n",
    "                v = np.abs((p-p_1)/(t-t_1))\n",
    "                v_d[i]=v\n",
    "                if(v<1.5):\n",
    "                    good_data.append(d[i])\n",
    "            good_data=np.array(good_data)\n",
    "            plt.plot(d_outlier[:,0]-d_outlier[0,0],d_outlier[:,1],'+')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'.')\n",
    "            plt.plot(good_data[:,0]-d_outlier[0,0],good_data[:,1],'-')\n",
    "            d_supahclean.append(good_data.copy())\n",
    "        else:\n",
    "            topics_mean[i] = 0\n",
    "            topics_std[i] = 0\n",
    "            d_supahclean.append(np.zeros((1,2)))\n",
    "    data_clean.append(d_supahclean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert to clean datasets (>3 measurements), fixed rate\n",
    "meas = []\n",
    "for n_i,n in enumerate(bag_names):\n",
    "    data = data_clean[n_i]\n",
    "    t0 = np.max([d[0,0] for d in data[:8]])\n",
    "    tend = np.min([d[-1,0] for d in data[:8]])\n",
    "    timesteps = np.arange(t0,tend,0.2)\n",
    "    measurements = np.zeros((timesteps.shape[0],len(topics)))\n",
    "    \n",
    "    for t_i, t in enumerate(timesteps):\n",
    "        for j in xrange(len(topics)):\n",
    "            d = data[j]\n",
    "            #get all matching data\n",
    "            idx = np.where((d[:,0]>=t) & (d[:,0]<t+0.2))[0]\n",
    "            if(idx.shape>0):\n",
    "                measurements[t_i,j] = np.median(d[idx,1])\n",
    "            else:\n",
    "                measurements[t_i,j] = 0 \n",
    "    meas.append(measurements[np.where(np.sum((measurements[:,:4]>1) & (measurements[:,:4]<10),1)>3)]) #how many valid measurements do we need?\n",
    "    #TODO: for multiple nodes, make sure each one has at least 3 (or 4 is better) ranging measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(meas[0][:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 48)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0472a772d24a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36msubplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/figure.pyc\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/axes.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m   9249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9250\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9251\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subplotspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9252\u001b[0m                 \u001b[1;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9253\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/pymodules/python2.7/matplotlib/gridspec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index out of range\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m                 \u001b[0mnum1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range"
     ]
    }
   ],
   "source": [
    "for n_i,n in enumerate(bag_names):\n",
    "    plt.figure()\n",
    "    m = meas[n_i]\n",
    "    print m.shape\n",
    "    for i,t in enumerate(topics):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.plot(m[:,i],'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create \"variables\"\n",
    "def cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Assumes x and y are Nx3, m and o are 1d vectors\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    cost_per_element = (dist_xy-(m-o))**2\n",
    "    total_cost = cost_per_element.sum()\n",
    "    return total_cost\n",
    "\n",
    "def derivative_cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Derivatives of the cost function wrt x,y and o\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    factor = 2*(dist_xy-(m-o))/dist_xy\n",
    "    #derivative with respect to x\n",
    "    deriv_x = factor.reshape((-1,1))*(x-y)\n",
    "    #derivative with respect to y\n",
    "    deriv_y = -deriv_x\n",
    "    #derivative with respect to o\n",
    "    deriv_o = factor*dist_xy\n",
    "    return deriv_x, deriv_y, deriv_o\n",
    "def create_data(fixed_nodes,floating_nodes,measurement_pairs,measurements):\n",
    "    '''\n",
    "        fixed nodes: indices in measurement_pairs corresponding to fixed nodes\n",
    "        floating nodes: indices in measurement_paris correspond to floating nodes\n",
    "        measurements pairs: each column in measurements corresponds to a distance between two nodes as specified by the rows in this matrix\n",
    "        measurements: num_measurements x num pairs observed distances\n",
    "        \n",
    "    '''\n",
    "    num_fixed = fixed_nodes.shape[0]\n",
    "    num_floating = floating_nodes.shape[0]\n",
    "    measurement_pairs = measurement_pairs.copy()\n",
    "    \n",
    "    #DOF = num_fixed #number of coordinates to find\n",
    "    #num_offsets = num_fixed*num_floating#number of offset variables to find (vector rows = fixed, columns = floating -> ravel)\n",
    "    \n",
    "    constraints = []\n",
    "    \n",
    "    variables = []\n",
    "    offsets = []\n",
    "    \n",
    "    for v in fixed_nodes:\n",
    "        variables.append((v,-1))\n",
    "    \n",
    "    #N = [ [x y z]_fixed[0] ... [x y z]_fixed[num_fixed-1] [x y z]_float[0,meas[0]] ...[x y z]_float[0,meas[k]] [x y z]_float[1,meas[0]]...\n",
    "    floating_node_to_coordinate_indices = [] #contains the indices in N for each valid measurement of a floating node\n",
    "    for i in xrange(num_floating):\n",
    "        \n",
    "        #select all measurement pair columns to/from this node\n",
    "        node = floating_nodes[i]\n",
    "        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #print i\n",
    "        #print node_dist_idx\n",
    "        #select all relevant measurements (columns)\n",
    "        node_meas = measurements[:,node_dist_idx]\n",
    "        #only keep valid measurements \n",
    "        node_meas_check = (node_meas>1) & (node_meas<20) #conservative for now\n",
    "        node_valid_distances = node_meas_check.sum(1)\n",
    "        #indices in node_meas\n",
    "        #select valid rows with a\n",
    "        node_meas_valid = np.where((node_valid_distances>3))[0] #only keep measurements with at least 4 valid distances\n",
    "        \n",
    "        for row_i,row in enumerate(node_meas_valid):\n",
    "            meas_row = measurements[row]\n",
    "            valid_cols = np.where(node_meas_check[row])[0]\n",
    "            valid_pairs = measurement_pairs[node_dist_idx[valid_cols],:]\n",
    "            meas_valid_row = meas_row[valid_cols]\n",
    "            #if(node==6):\n",
    "            #print node_dist_idx\n",
    "            #print valid_pairs\n",
    "            #print measurement_pairs[node_dist_idx[valid_cols],:]\n",
    "            #print \"\"\n",
    "            for col_i, col in enumerate(valid_cols):\n",
    "                pair = np.sort(valid_pairs[col_i])\n",
    "                \n",
    "                #make sure we have allocated a variable for each measurement\n",
    "                \n",
    "                if(pair[0] in fixed_nodes):\n",
    "                    if(not (pair[0],-1) in variables):\n",
    "                        variables.append((pair[0],-1))\n",
    "                elif(not (pair[0],row) in variables): #create new variable for this observation?\n",
    "                    variables.append((pair[0],row))\n",
    "                \n",
    "                if(pair[1] in fixed_nodes):\n",
    "                    if(not (pair[1],-1) in variables):\n",
    "                        variables.append((pair[0],-1))\n",
    "                elif(not tuple((pair[1],row)) in variables): #create new variable for this observation?\n",
    "                    variables.append((pair[1],row)) \n",
    "                #is there an existing offset variable for this measurement pair?\n",
    "                if(not tuple(pair) in offsets):\n",
    "                    offsets.append(tuple(pair))\n",
    "                    \n",
    "                if(pair[0] in fixed_nodes):\n",
    "                    v0 = (pair[0],-1)\n",
    "                else:\n",
    "                    v0 = (pair[0],row)\n",
    "                if(pair[1] in fixed_nodes):\n",
    "                    v1 = (pair[1],-1)\n",
    "                else:\n",
    "                    v1 = (pair[1],row)\n",
    "                \n",
    "                if(pair[0] in floating_nodes and pair[1] in floating_nodes):\n",
    "                        print \"floating node to floating node measurements\"\n",
    "                \n",
    "                m = meas_row[node_dist_idx[col]]\n",
    "                constraints.append((variables.index(v0),variables.index(v1),m,offsets.index(tuple(pair))))\n",
    "                \n",
    "                    \n",
    "\n",
    "        #floating_node_to_coordinate_indices.append(node_meas_valid+DOF)    \n",
    "        #DOF += node_meas_valid.shape[0] #every valid measurement adds a coordinate (3D)\n",
    "    \n",
    "    DOF = len(variables)\n",
    "    num_offsets = len(offsets)\n",
    "    #print variables\n",
    "    #print offsets\n",
    "    \n",
    "    N_to_CSTR_X = np.zeros((len(constraints),DOF))\n",
    "    N_to_CSTR_Y = np.zeros(N_to_CSTR_X.shape)\n",
    "    o_to_CSTR = np.zeros((len(constraints),num_offsets))\n",
    "    #print num_offsets\n",
    "    m = np.zeros(len(constraints))\n",
    "    for i in xrange(len(constraints)):\n",
    "        N_to_CSTR_X[i,constraints[i][0]] = 1\n",
    "        N_to_CSTR_Y[i,constraints[i][1]] = 1\n",
    "        m[i] = constraints[i][2]\n",
    "        #print constraints[i]\n",
    "        o_to_CSTR[i,constraints[i][3]] = 1\n",
    "    \n",
    "    \n",
    "    def deriv_func(N,o):\n",
    "        X = N_to_CSTR_X.dot(N)\n",
    "        Y = N_to_CSTR_Y.dot(N)\n",
    "        O = o_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        dX,dY,dO = derivative_cost_function(X,Y,m.ravel(),O.ravel())\n",
    "        dN = N_to_CSTR_X.T.dot(dX) +  N_to_CSTR_Y.T.dot(dY)\n",
    "        dN[0,:] = 0\n",
    "        dN[1,1:] = 0\n",
    "        dN[2,2] = 0\n",
    "        do = o_to_CSTR.T.dot(dO.reshape((-1,1))).ravel()\n",
    "        return dN,do\n",
    "    \n",
    "    def cost_func(N,o):\n",
    "        X = N_to_CSTR_X.dot(N)\n",
    "        Y = N_to_CSTR_Y.dot(N)\n",
    "        O = o_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        return cost_function(X,Y,m.ravel(),O.ravel())\n",
    "        \n",
    "    \n",
    "    #create m vector\n",
    "    return deriv_func,cost_func, len(variables), len(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061.06009073\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.153193\n",
      "         Iterations: 221\n",
      "         Function evaluations: 278\n",
      "         Gradient evaluations: 269\n",
      "0.153193016845\n"
     ]
    }
   ],
   "source": [
    "#WORKING VERSION: USE THIS ONE JONATHAN!!!\n",
    "fixed_nodes = np.array([15,13,16,14],dtype=int)\n",
    "floating_nodes = np.array([2],dtype=int)#,2],dtype=int)\n",
    "dist_pairs = np.array([[2,13],[2,14],[2,15],[2,16],],dtype=int)\n",
    "                       #np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "\n",
    "a = np.arange(meas[0].shape[0])\n",
    "np.random.shuffle(a)\n",
    "m = meas[0][a[::5],:]#[:,(0,1,2,3,4,5,6,8)]\n",
    "#m = np.hstack((m,np.ones((m.shape[0],1))*1.36))\n",
    "df,cf,DOF,num_offsets = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "N,o = np.random.randn(DOF,3)*3,np.zeros(num_offsets)+3.5\n",
    "N[0] = 0\n",
    "N[1,1:] = 0\n",
    "N[2,2] = 0     \n",
    "#B=np.array([[ 0.,          0.,          0.        ],\n",
    "#                 [ -3.38,  0.,          0.        ],\n",
    "#                 [ -0.7039,  -2.189,  0.        ]])\n",
    "B = np.array([[0,0,0],\n",
    "             [-5.35,0,0],\n",
    "             [.96,-2.35,0]])\n",
    "N[:3] = B\n",
    "\n",
    "dN,do = df(N,o)\n",
    "print cf(N,o)\n",
    "\n",
    "import scipy.optimize as so\n",
    "Nf = N.ravel()\n",
    "X_initial = np.hstack((Nf,o))\n",
    "def cost_fun(x):\n",
    "    Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "    Nt[:3] = B\n",
    "    reg = 0.05*np.sum((x[-o.shape[0]:]-3.5)**2)#+0.5*(x[11]-2.5)**2#+0.05*(x[10]-2.)**2+0.05*(x[9]-2.)**2\n",
    "    return cf(Nt ,x[-o.shape[0]:])+reg\n",
    "def cost_grad(x):\n",
    "    dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "    dN[:3] = 0\n",
    "    #do[:] = 0\n",
    "    do += 0.05*2*(x[-o.shape[0]:]-3.5)\n",
    "    dN = dN.ravel()\n",
    "    #dN[11] += 0.5*2*(x[11]-2.5)\n",
    "    #dN[10] += 0.05*2*(x[10]-2.)\n",
    "    #dN[9] += 0.05*2*(x[9]-2.)\n",
    "    return np.hstack((dN,do))\n",
    "\n",
    "resall = []\n",
    "def progress(x):\n",
    "    resall.append(x)\n",
    "\n",
    "res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=10,gtol=1e-10,callback=progress)\n",
    "print cost_fun(res)\n",
    "#    #print res[:-o.shape[0]].reshape((DOF,3))[:N_target.shape[0]].round(2)\n",
    "#    #print N_target.round(2)\n",
    "#    #print np.sort(res[-o.shape[0]:].round(2))\n",
    "#    #print np.sort(o_target.round(2))\n",
    "#all_results.append((o_target.copy(),res[-o.shape[0]:].copy(),cost_fun(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.18787562,  3.58978245,  4.12752976,  3.73947614])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-4:]\n",
    "#array([ 4.13215675,  3.67599784,  4.18511672,  3.83472233])\n",
    "#array([ 4.22836493,  3.80866668,  4.07504397,  3.75225553])\n",
    "#array([ 4.18787562,  3.58978245,  4.12752976,  3.73947614]) #0.15 #[15,13,16,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.19  3.59  4.13  3.74]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Patch3DCollection at 0x7f30d04f80d0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [-5.35      ,  0.        ,  0.        ],\n",
       "       [ 0.96      , -2.35      ,  0.        ],\n",
       "       [-2.71297727, -0.617745  , -2.3072566 ]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p\n",
    "#array([[ 0.        ,  0.        ,  0.        ],\n",
    "#       [-5.35      ,  0.        ,  0.        ],\n",
    "#       [ 0.96      , -2.35      ,  0.        ],\n",
    "#       [-2.71297727, -0.617745  , -2.3072566 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.66324529,  3.30318086,  5.90031792],\n",
       "       [ 3.66324529,  0.        ,  4.74821996,  3.60090027],\n",
       "       [ 3.30318086,  4.74821996,  0.        ,  7.24703045],\n",
       "       [ 5.90031792,  3.60090027,  7.24703045,  0.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.spatial as ss\n",
    "ss.distance.squareform(ss.distance.pdist(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.19  3.59  4.13  3.74]\n"
     ]
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for it in xrange(len(resall)):\n",
    "    p = resall[it][:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "    #p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:]\n",
    "    ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "#ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.65 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 382 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "Nt = X_initial[:-o.shape[0]].reshape((DOF,3))\n",
    "%timeit df(Nt ,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create \"variables\"\n",
    "def cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Assumes x and y are Nx3, m and o are 1d vectors\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    cost_per_element = (dist_xy-(m-o))**2\n",
    "    total_cost = cost_per_element.sum()\n",
    "    return total_cost\n",
    "\n",
    "def derivative_cost_function(x,y,m,o):\n",
    "    '''\n",
    "        Derivatives of the cost function wrt x,y and o\n",
    "    '''\n",
    "    dist_xy = np.sqrt(np.sum((x-y)**2,1)) #1d vector\n",
    "    factor = 2*(dist_xy-(m-o))/dist_xy\n",
    "    #derivative with respect to x\n",
    "    deriv_x = factor.reshape((-1,1))*(x-y)\n",
    "    #derivative with respect to y\n",
    "    deriv_y = -deriv_x\n",
    "    #derivative with respect to o\n",
    "    deriv_o = factor*dist_xy\n",
    "    return deriv_x, deriv_y, deriv_o\n",
    "def create_data(fixed_nodes,floating_nodes,measurement_pairs,measurements):\n",
    "    '''\n",
    "        fixed nodes: indices in measurement_pairs corresponding to fixed nodes\n",
    "        floating nodes: indices in measurement_paris correspond to floating nodes\n",
    "        measurements pairs: each column in measurements corresponds to a distance between two nodes as specified by the rows in this matrix\n",
    "        measurements: num_measurements x num pairs observed distances\n",
    "        \n",
    "    '''\n",
    "    num_fixed = fixed_nodes.shape[0]\n",
    "    num_floating = floating_nodes.shape[0]\n",
    "    num_measurements = measurements.shape[0]\n",
    "    measurement_pairs = measurement_pairs.copy()\n",
    "    \n",
    "    floating_to_fixed = {} #contains an array of indices in measurement_pairs for each node\n",
    "    floating_to_floating = {} #similar\n",
    "    bars = {1:(2,1.37),3:(4,1.37),5:(6,1.37),7:(8,1.37),9:(10,1.37),11:(12,1.37)} #nodes with bar connections: FROM: (TO,LENGTH)\n",
    "    \n",
    "    #for each floating node, find the measurement pairs to fixed nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_fixed[node] = []        \n",
    "        for i in node_dist_idx:\n",
    "            if(measurement_pairs[i,0] in fixed_nodes or measurement_pairs[i,1] in fixed_nodes):\n",
    "                #found one\n",
    "                floating_to_fixed[node].append(i)\n",
    "                \n",
    "    #for each floating node, find the measurement pairs to other floating nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        #get measurement columns corresponding to this node (to/from)        \n",
    "        node_dist_idx = np.where((measurement_pairs[:,0] == node) | (measurement_pairs[:,1] == node))[0]\n",
    "        #create new array\n",
    "        floating_to_floating[node] = []        \n",
    "        for pair_idx in node_dist_idx:\n",
    "            #to prevent doubles, we only add pairs originating FROM this node TO another floating node\n",
    "            if((measurement_pairs[pair_idx,0] == node) and measurement_pairs[pair_idx,1] in floating_nodes):\n",
    "                #found one\n",
    "                floating_to_floating[node].append(pair_idx)\n",
    "    \n",
    "    \n",
    "    #Find all the floating node positions with enough measurements for ranging\n",
    "    #enough means more than 3 valid measurements to fixed nodes\n",
    "    floating_valid_points = np.zeros((num_measurements,num_floating),dtype=bool)\n",
    "    measurements_valid = (measurements>1) & (measurements<20) #this matrix contains a one for each valid measurements\n",
    "    #a one in the above matrix indicates that there are enough valid measurements between a floating node and fixed nodes available for the \n",
    "    #columns correspond to indices in floating_nodes\n",
    "    for node_idx, node in enumerate(floating_nodes):\n",
    "        for timestep_idx in xrange(num_measurements):\n",
    "            #get all measurements to fixed nodes from this node\n",
    "            to_fixed = floating_to_fixed[node]\n",
    "            valid_cnt = 0\n",
    "            for pair_idx in to_fixed:\n",
    "                if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                    #this is a valid measurement, use it\n",
    "                    valid_cnt += 1\n",
    "            if(valid_cnt >= 4):\n",
    "                #we can estimate this location at this timestep\n",
    "                floating_valid_points[timestep_idx,node_idx] = True\n",
    "\n",
    "    #we now know all the valid coordinates to estimate, so we are ready to create constraints\n",
    "        \n",
    "    #print floating_to_fixed\n",
    "    #print floating_to_floating\n",
    "        \n",
    "    #create distance constraints between floating nodes and fixed nodes for all valid time steps with valid measurements per floating node\n",
    "    constraints = []\n",
    "    \n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                #This is a valid measurement timestep, \n",
    "                #add a constraint for each valid measurement to the respective anchor.\n",
    "                to_fixed = floating_to_fixed[node]\n",
    "                for pair_idx in to_fixed:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        constraints.append((\"float_to_fixed\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                #add constraints to other valid floating nodes\n",
    "                to_floating = floating_to_floating[node]\n",
    "                for pair_idx in to_floating:\n",
    "                    if(measurements_valid[timestep_idx,pair_idx]):\n",
    "                        pair = measurement_pairs[pair_idx]\n",
    "                        from_ = np.where(floating_nodes == pair[0])[0][0]\n",
    "                        to_ = np.where(floating_nodes == pair[1])[0][0]\n",
    "                        if(floating_valid_points[timestep_idx,from_] and floating_valid_points[timestep_idx,to_]): #make sure destination node is valid at the current timestep\n",
    "                            \n",
    "                            constraints.append((\"float_to_float\",\n",
    "                                            measurement_pairs[pair_idx],\n",
    "                                            measurements[timestep_idx,pair_idx],\n",
    "                                            timestep_idx))\n",
    "                        \n",
    "                #add bar constraints\n",
    "                if(node in bars):\n",
    "                    b = bars[node]\n",
    "                    bar_node = b[0]\n",
    "                    #check whether destination node location is valid at this timestep\n",
    "                    if(floating_valid_points[timestep_idx,np.where(floating_nodes == bar_node)[0][0]]):\n",
    "                        #ok, we can add the constraint\n",
    "                        constraints.append((\"bar\",\n",
    "                                            [node,bar_node],\n",
    "                                            b[1],\n",
    "                                           timestep_idx))\n",
    "    \n",
    "    #create variables (this is the fun part)\n",
    "    variable_to_node = [] #indicates which variable corresponds to which node\n",
    "    for n in fixed_nodes:\n",
    "        variable_to_node.append(n) #first indices are fixed nodes\n",
    "    for timestep_idx in xrange(num_measurements): #iterate over time steps\n",
    "        for node_idx, node in enumerate(floating_nodes): #iterate over nodes\n",
    "            if(floating_valid_points[timestep_idx,node_idx]):\n",
    "                variable_to_node.append((node,timestep_idx)) #we store the floating nodes as node, timestep tuples\n",
    "    variable_to_node_map = {}\n",
    "    for v_idx,v in enumerate(variable_to_node):\n",
    "        variable_to_node_map[v] = v_idx\n",
    "    \n",
    "    #print len(variable_to_node)\n",
    "    \n",
    "    offset_variable_to_pair = [] #offset variables: pairs of nodes == tricky\n",
    "    for c in constraints:\n",
    "        #find out if we already have an offset variable for this constraint pair\n",
    "        if(not c[0]==\"bar\"): #bar constraints don't have offsets\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            if(not pair in offset_variable_to_pair):\n",
    "                offset_variable_to_pair.append(pair)\n",
    "    \n",
    "    num_offsets = len(offset_variable_to_pair)\n",
    "    num_variables = len(variable_to_node)\n",
    "    num_constraints = len(constraints)\n",
    "    \n",
    "    #print len(offset_variable_to_pair)\n",
    "    #TODO: constraints\n",
    "    #print len(constraints)\n",
    "    \n",
    "    #Generate the measurement vector, variable to constraint matrices and offset to constraint matrices\n",
    "    measurement_vector = np.zeros(num_constraints)\n",
    "    variables_to_CSTR_X = np.zeros((num_constraints,num_variables))\n",
    "    variables_to_CSTR_Y = np.zeros(variables_to_CSTR_X.shape)\n",
    "    offsets_to_CSTR = np.zeros((num_constraints,num_offsets))\n",
    "    #print floating_valid_points\n",
    "    for c_idx,c in enumerate(constraints):\n",
    "        measurement_vector[c_idx] = c[2]\n",
    "        #find the correct offset variable\n",
    "        if(c[0]==\"bar\"):\n",
    "            #bar constraints don't have offsets\n",
    "            offsets_to_CSTR[c_idx,:] = 0 \n",
    "        else:\n",
    "            pair = tuple(np.sort(c[1]))\n",
    "            offset_idx = offset_variable_to_pair.index(pair)\n",
    "            offsets_to_CSTR[c_idx,offset_idx] = 1 \n",
    "        #find the correct nodal coordinate variables\n",
    "        if(c[0]==\"bar\" or c[0]==\"float_to_float\"):\n",
    "            #print c\n",
    "            from_ = tuple((c[1][0],c[3])) #node,timestep\n",
    "            to_ = tuple((c[1][1],c[3]))\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        else:\n",
    "            #float to fixed\n",
    "            if(c[1][0] in fixed_nodes):\n",
    "                from_ = c[1][0]\n",
    "                to_ = tuple((c[1][1],c[3]))\n",
    "            else:\n",
    "                from_ = tuple((c[1][0],c[3]))\n",
    "                to_ = c[1][1]\n",
    "\n",
    "            from_idx = variable_to_node_map[from_]\n",
    "            to_idx = variable_to_node_map[to_]\n",
    "            variables_to_CSTR_X[c_idx,from_idx] = 1\n",
    "            variables_to_CSTR_Y[c_idx,to_idx] = 1\n",
    "        #variables_to_CSTR_X[c_idx,variable_to_node.index(c[1][0])] = 1\n",
    "        #variables_to_CSTR_Y[c_idx,variable_to_node.index(c[1][1])] = 1\n",
    "        \n",
    "        \n",
    "    def deriv_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        #print X.shape\n",
    "        #print Y.shape\n",
    "        #print O.shape\n",
    "        #print m.shape\n",
    "        dX,dY,dO = derivative_cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "        dN = variables_to_CSTR_X.T.dot(dX) +  variables_to_CSTR_Y.T.dot(dY)\n",
    "        dN[0,:] = 0\n",
    "        dN[1,1:] = 0\n",
    "        dN[2,2] = 0\n",
    "        do = offsets_to_CSTR.T.dot(dO.reshape((-1,1))).ravel()\n",
    "        return dN,do\n",
    "    \n",
    "    def cost_func(N,o):\n",
    "        X = variables_to_CSTR_X.dot(N)\n",
    "        Y = variables_to_CSTR_Y.dot(N)\n",
    "        O = offsets_to_CSTR.dot(o.reshape((num_offsets,1))) \n",
    "        return cost_function(X,Y,measurement_vector.ravel(),O.ravel())\n",
    "    \n",
    "    #print offsets_to_CSTR\n",
    "    #print variables_to_CSTR_X\n",
    "    #create m vector\n",
    "    return deriv_func,cost_func, num_variables, num_offsets, variable_to_node, variable_to_node_map, offset_variable_to_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.36969788204\n",
      "2.97924200794\n",
      "8.27403102939\n",
      "2.60201477858\n",
      "0.493782780834\n",
      "2.52449036854\n",
      "2.40353798186\n",
      "2.33027223911\n",
      "3.31721053443\n",
      "1.14663638482\n",
      "2.48245514531\n",
      "0.58607511906\n",
      "2.53330057818\n",
      "1.91627956952\n",
      "2.48462792748\n",
      "2.03775297242"
     ]
    }
   ],
   "source": [
    "cf = 10\n",
    "cf_min = cf\n",
    "while cf>0.1:\n",
    "    fixed_nodes = np.array([15,13,16,14],dtype=int)\n",
    "    floating_nodes = np.array([2,1],dtype=int)#,2],dtype=int)\n",
    "    #dist_pairs = np.array([[2,13],[2,14],[2,15],[2,16],[1,13],[1,14],[1,15],[1,16]],dtype=int)\n",
    "                           #np.array([[1,10],[2,10],[4,10],[7,10],[8,10],[12,10],[13,10],[16,10]],dtype=int)\n",
    "    dist_pairs = topics_node_to_node[:8]\n",
    "\n",
    "    a = np.arange(meas[0].shape[0])\n",
    "    np.random.shuffle(a)\n",
    "    m = meas[0][a[::5],:]#[:,(0,1,2,3,4,5,6,8)]\n",
    "    #m = np.hstack((m,np.ones((m.shape[0],1))*1.36))\n",
    "    df,cf,DOF,num_offsets,variable_to_node,variable_to_node_map, offset_variable_to_pair  = create_data(fixed_nodes,floating_nodes,dist_pairs,m)\n",
    "\n",
    "    N,o = np.random.randn(DOF,3)*3,np.zeros(num_offsets)+3.5\n",
    "    N[0] = 0\n",
    "    N[1,1:] = 0\n",
    "    N[2,2] = 0     \n",
    "    #B=np.array([[ 0.,          0.,          0.        ],\n",
    "    #                 [ -3.38,  0.,          0.        ],\n",
    "    #                 [ -0.7039,  -2.189,  0.        ]])\n",
    "    B = np.array([[0,0,0],\n",
    "                 [-5.35,0,0],\n",
    "                 [.96,-2.35,0]])\n",
    "    N[:3] = B\n",
    "\n",
    "    dN,do = df(N,o)\n",
    "    #print cf(N,o)\n",
    "\n",
    "    import scipy.optimize as so\n",
    "    Nf = N.ravel()\n",
    "    X_initial = np.hstack((Nf,o))\n",
    "    def cost_fun(x):\n",
    "        Nt = x[:-o.shape[0]].reshape((DOF,3))\n",
    "        Nt[:3] = B\n",
    "        reg = 0.05*np.sum((x[-o.shape[0]:]-3.5)**2)#+0.5*(x[11]-2.5)**2#+0.05*(x[10]-2.)**2+0.05*(x[9]-2.)**2\n",
    "        return cf(Nt ,x[-o.shape[0]:])+reg\n",
    "    def cost_grad(x):\n",
    "        dN,do = df(x[:-o.shape[0]].reshape((DOF,3)),x[-o.shape[0]:])\n",
    "        dN[:3] = 0\n",
    "        #do[:] = 0\n",
    "        do += 0.05*2*(x[-o.shape[0]:]-3.5)\n",
    "        dN = dN.ravel()\n",
    "        #dN[11] += 0.5*2*(x[11]-2.5)\n",
    "        #dN[10] += 0.05*2*(x[10]-2.)\n",
    "        #dN[9] += 0.05*2*(x[9]-2.)\n",
    "        return np.hstack((dN,do))\n",
    "\n",
    "\n",
    "    resall = []\n",
    "    def progress(x):\n",
    "        resall.append(x)\n",
    "\n",
    "    res = so.fmin_bfgs(cost_fun,X_initial,fprime=cost_grad,disp=0,gtol=1e-10,callback=progress)\n",
    "    cf = cost_fun(res)\n",
    "    if(cf<cf_min):\n",
    "        res_min = res.copy()\n",
    "        cf_min = cf\n",
    "    print cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.17  3.47  4.12  3.8   4.1   3.52  4.14  3.8 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Patch3DCollection at 0x7f30d0f38750>"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print res[-o.shape[0]:].round(2)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "p = res[:-dist_pairs.shape[0]].reshape((DOF,3))[:fixed_nodes.shape[0]]\n",
    "p2 = res[:-dist_pairs.shape[0]].reshape((DOF,3))[fixed_nodes.shape[0]:]\n",
    "ax.scatter(p[:,0],p[:,1],p[:,2],c='b')\n",
    "for i in xrange(fixed_nodes.shape[0]):\n",
    "    ax.text(p[i,0],p[i,1],p[i,2],fixed_nodes[i])\n",
    "\n",
    "ax.scatter(p2[:,0],p2[:,1],p2[:,2],c='y')\n",
    "#ax.scatter(pc[:,0],pc[:,1],pc[:,2],c='b')\n",
    "#ax.scatter(p2c[:,0],p2c[:,1],p2c[:,2],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_to_node_map[(2,14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3687217997872911"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = res[:-dist_pairs.shape[0]].reshape((DOF,3))\n",
    "np.linalg.norm(p_all[20]-p_all[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [-5.35      ,  0.        ,  0.        ],\n",
       "       [ 0.96      , -2.35      ,  0.        ],\n",
       "       [-2.82540204, -0.99646462,  2.4192616 ]])"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
